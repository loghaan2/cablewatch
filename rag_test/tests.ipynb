{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2d7f80",
   "metadata": {},
   "source": [
    "# Tests on the RAG injection and queries asks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81df45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25cbd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os \n",
    "#from pydub import AudioSegment\n",
    "import subprocess\n",
    "import os\n",
    "from loguru import logger\n",
    "from pyannote.audio import Pipeline \n",
    "from google.cloud import speech_v2\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd6f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyannote.audio in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (3.4.0)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.13.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (0.36.0)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core<6.0,>=5.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database<6.0,>=5.0.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics<4.0,>=3.2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline<4.0,>=3.0.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch_metric_learning>=2.1.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.9.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (14.2.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (3.0.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.6.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.8.0)\n",
      "Requirement already satisfied: torch_audiomentations>=0.11.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (2.8.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.audio) (1.8.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (6.0.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote.audio) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote.audio) (1.16.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote.audio) (4.15.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.database<6.0,>=5.0.1->pyannote.audio) (2.2.3)\n",
      "Requirement already satisfied: typer>=0.12.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.database<6.0,>=5.0.1->pyannote.audio) (0.21.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.8.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (3.10.8)\n",
      "Requirement already satisfied: sympy>=1.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.14.0)\n",
      "Requirement already satisfied: optuna>=3.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (4.6.0)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: filelock>=3.0.10 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote.audio) (2025.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: requests in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote.audio) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from lightning>=2.0.1->pyannote.audio) (0.15.2)\n",
      "Requirement already satisfied: pytorch-lightning in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from lightning>=2.0.1->pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.13.2)\n",
      "Requirement already satisfied: setuptools in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (80.9.0)\n",
      "Requirement already satisfied: networkx in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch>=2.0.0->pyannote.audio) (3.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (1.17.2)\n",
      "Requirement already satisfied: colorlog in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (2.0.45)\n",
      "Requirement already satisfied: Mako in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pandas>=0.19->pyannote.database<6.0,>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from pandas>=0.19->pyannote.database<6.0,>=5.0.1->pyannote.audio) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from rich>=12.0.0->pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from soundfile>=0.12.1->pyannote.audio) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.23)\n",
      "Requirement already satisfied: hyperpyyaml in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from sympy>=1.1->pyannote.metrics<4.0,>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: primePy>=1.3 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote.audio) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.17)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.15 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jeanlsoto54/.pyenv/versions/3.13.9/envs/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote.audio) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d0a36",
   "metadata": {},
   "source": [
    "## Process of transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215442a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jeanlsoto54/code/jeanluissoto/project_final/cablewatch/data/ingest/segment_2025-12-24_16h36mn50.mp3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to open the ffmpeg and convert the ts into mp3 \n",
    "def convert_ts_to_mp3_direct(ts_file):\n",
    "    mp3_file = ts_file.replace('.ts', '.mp3')\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", ts_file, \n",
    "        \"-vn\", \n",
    "        \"-acodec\", \"libmp3lame\", \n",
    "        \"-y\", \n",
    "        mp3_file\n",
    "    ]\n",
    "    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    return mp3_file\n",
    "\n",
    "audio_test =\"/home/jeanlsoto54/code/jeanluissoto/project_final/cablewatch/data/ingest/segment_2025-12-24_16h36mn50.ts\"\n",
    "convert_ts_to_mp3_direct(audio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543d6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "groq_api_key = getpass.getpass('API key here:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09353545",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/jeanlsoto54/code/jeanluissoto/project_final/cablewatch/data/ingest/segment_2025-12-24_16h36mn50.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ed4ae",
   "metadata": {},
   "source": [
    "Méthode OpenAI, modèle : Whisper v3 (avec une inférence exécutée sur Groq, pour la vitesse et la puissance de ce modèle open source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ab1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcription_groqwhisper(api_key, filename):\n",
    "  inicio = time.time()\n",
    "  client = Groq(api_key=api_key)\n",
    "  \n",
    "\n",
    "  with open(filename, \"rb\") as file:\n",
    "      transcription = client.audio.transcriptions.create(\n",
    "        file=(filename, file.read()),\n",
    "        model=\"whisper-large-v3-turbo\",\n",
    "        temperature=0,\n",
    "        response_format=\"verbose_json\",\n",
    "        language='fr',\n",
    "        timestamp_granularities=['segment']\n",
    "      )\n",
    "  fin = time.time()\n",
    "  logger.info(f\"Transcription completed in {fin - inicio:.2f} seconds\")\n",
    "  return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0069d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 21:41:00.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtranscription_groqwhisper\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mTranscription completed in 1.14 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transcription = transcription_groqwhisper(groq_api_key,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b650abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Cornu. Bonsoir. Jusqu'à 7 millions de téléspectateurs suivent cette interview. Un record historique. Qui se présente devant nous ce soir ? Est-ce l'ex-premier ministre ? Le futur premier ministre ? Un médiateur ? Qui ? Le premier ministre qui a démissionné, qui a remis la démission du gouvernement lundi matin, donc j'expédie les affaires courantes. Il est vrai que depuis 48 heures, le président de la République m'a fait revenir lundi après-midi, considérant que les trois semaines que j'avais passées dans le secret, parfois ou plus ou moins publiquement avec les différents\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc906757",
   "metadata": {},
   "source": [
    "GCP Modele: Speech-to-Text (V2) solution avec couts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c7098",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Operation' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m      5\u001b[39m create_request = speech_v2.types.CreateRecognizerRequest(\n\u001b[32m      6\u001b[39m     parent=\u001b[33m\"\u001b[39m\u001b[33mprojects/teak-instrument-480811-u5/locations/europe-west4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     recognizer_id=\u001b[33m\"\u001b[39m\u001b[33mmy-diarization-recognizer\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# HYPHEN not underscore\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     ),\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m recognizer = client.create_recognizer(request=create_request)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Operation' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v2\n",
    "\n",
    "client = speech_v2.SpeechClient(client_options={\"api_endpoint\": \"europe-west4-speech.googleapis.com\"})\n",
    "\n",
    "create_request = speech_v2.types.CreateRecognizerRequest(\n",
    "    parent=\"projects/teak-instrument-480811-u5/locations/europe-west4\",\n",
    "    recognizer_id=\"my-diarization-recognizer\",  # HYPHEN not underscore\n",
    "    recognizer=speech_v2.types.Recognizer(\n",
    "        display_name=\"French Diarization Recognizer\",\n",
    "        model=\"latest_long\",\n",
    "        default_recognition_config=speech_v2.types.RecognitionConfig(\n",
    "            auto_decoding_config={},\n",
    "            language_codes=[\"fr-FR\"],\n",
    "            model=\"latest_long\",\n",
    "            features=speech_v2.types.RecognitionFeatures(\n",
    "                enable_automatic_punctuation=True,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "recognizer = client.create_recognizer(request=create_request)\n",
    "print(f\"Created: {recognizer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9e1e570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: projects/910491225982/locations/europe-west4/recognizers/my-diarization-recognizer, Model: latest_long, Supports Diarization: True\n"
     ]
    }
   ],
   "source": [
    "client = speech_v2.SpeechClient(client_options={\"api_endpoint\": \"europe-west4-speech.googleapis.com\"})\n",
    "parent = \"projects/teak-instrument-480811-u5/locations/europe-west4\"\n",
    "recognizers = client.list_recognizers(parent=parent)\n",
    "for r in recognizers:\n",
    "    print(f\"ID: {r.name}, Model: {r.model}, Supports Diarization: {hasattr(r.default_recognition_config.features, 'diarization_config')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf74d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_gcp(\n",
    "        filename\n",
    "):\n",
    "    \n",
    "\n",
    "    project_id = \"teak-instrument-480811-u5\"\n",
    "    location = \"europe-west4\"  \n",
    "    recognizer_id = \"my-diarization-recognizer\"  # Your custom recognizer\n",
    "    client_options = {\"api_endpoint\": f\"{location}-speech.googleapis.com\"}\n",
    "    recognizer_path = f\"projects/{project_id}/locations/{location}/recognizers/{recognizer_id}\"\n",
    "    \n",
    "    client = speech_v2.SpeechClient(client_options=client_options)\n",
    "    \n",
    "    config = speech_v2.types.RecognitionConfig(\n",
    "        auto_decoding_config={},\n",
    "        language_codes=[\"fr-FR\"],\n",
    "        # features=speech_v2.types.RecognitionFeatures(\n",
    "        #     diarization_config=speech_v2.types.SpeakerDiarizationConfig(\n",
    "        #         min_speaker_count=1,\n",
    "        #         max_speaker_count=5,)\n",
    "            \n",
    "        # )\n",
    "    )\n",
    "\n",
    "    inicio = time.time()\n",
    "    with open(filename, 'rb') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    request = speech_v2.types.RecognizeRequest(\n",
    "        recognizer=recognizer_path,\n",
    "        config=config,\n",
    "        content=content,\n",
    "    )\n",
    "    response = client.recognize(request=request)\n",
    "    logger.info(response)\n",
    "\n",
    "    billed_duration = response.metadata.total_billed_duration.seconds\n",
    "\n",
    "    script_final = []\n",
    "    current_speaker = None\n",
    "    current_sentence = \"\"\n",
    "\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            speaker = word_info.speaker_label or \"Unknown\"\n",
    "            word = word_info.word\n",
    "\n",
    "            if speaker != current_speaker:\n",
    "                if current_speaker is not None:\n",
    "                    script_final.append(f\"Locuteur {current_speaker}: {current_sentence.strip()}\")\n",
    "                current_speaker = speaker\n",
    "                current_sentence = word + \" \"\n",
    "            else:\n",
    "                current_sentence += word + \" \"\n",
    "\n",
    "    if current_sentence:\n",
    "        script_final.append(f\"Locuteur {current_speaker}: {current_sentence.strip()}\")\n",
    "    \n",
    "    fin = time.time()\n",
    "    logger.info(f\"Transcription completed in {fin - inicio:.2f} seconds\")\n",
    "    return script_final, billed_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f2bf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_gcp(\n",
    "        filename\n",
    "):\n",
    "    \n",
    "\n",
    "    project_id = \"teak-instrument-480811-u5\"\n",
    "    location = \"eu\"  \n",
    "    recognizer_id = \"_\"  # Your custom recognizer\n",
    "    client_options = {\"api_endpoint\": f\"{location}-speech.googleapis.com\"}\n",
    "    recognizer_path = f\"projects/{project_id}/locations/{location}/recognizers/{recognizer_id}\"\n",
    "    \n",
    "    client = speech_v2.SpeechClient(client_options=client_options)\n",
    "    \n",
    "    config = speech_v2.types.RecognitionConfig(\n",
    "        auto_decoding_config={},\n",
    "        language_codes=[\"fr-FR\"],\n",
    "        model=\"chirp_3\",\n",
    "        features=speech_v2.types.RecognitionFeatures(\n",
    "            diarization_config=speech_v2.types.SpeakerDiarizationConfig(\n",
    "                min_speaker_count=1,\n",
    "                max_speaker_count=5,)\n",
    "            \n",
    "        )\n",
    "    )\n",
    "\n",
    "    inicio = time.time()\n",
    "    with open(filename, 'rb') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    request = speech_v2.types.RecognizeRequest(\n",
    "        recognizer=recognizer_path,\n",
    "        config=config,\n",
    "        content=content,\n",
    "    )\n",
    "    response = client.recognize(request=request)\n",
    "    logger.info(response)\n",
    "\n",
    "    billed_duration = response.metadata.total_billed_duration.seconds\n",
    "\n",
    "    script_final = []\n",
    "    current_speaker = None\n",
    "    current_sentence = \"\"\n",
    "\n",
    "    for result in response.results:\n",
    "        for word_info in result.alternatives[0].words:\n",
    "            speaker = word_info.speaker_label or \"Unknown\"\n",
    "            word = word_info.word\n",
    "\n",
    "            if speaker != current_speaker:\n",
    "                if current_speaker is not None:\n",
    "                    script_final.append(f\"Locuteur {current_speaker}: {current_sentence.strip()}\")\n",
    "                current_speaker = speaker\n",
    "                current_sentence = word + \" \"\n",
    "            else:\n",
    "                current_sentence += word + \" \"\n",
    "\n",
    "    if current_sentence:\n",
    "        script_final.append(f\"Locuteur {current_speaker}: {current_sentence.strip()}\")\n",
    "    \n",
    "    fin = time.time()\n",
    "    logger.info(f\"Transcription completed in {fin - inicio:.2f} seconds\")\n",
    "    return script_final, billed_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "39fcac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 23:07:38.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtranscription_gcp\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mmetadata {\n",
      "  total_billed_duration {\n",
      "    seconds: 31\n",
      "  }\n",
      "  request_id: \"82e569a3-0000-2ed2-8511-582429ce8efc\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Cornu. Bonsoir. Jusqu\\'à 7 millions de téléspectateurs suivent cette interview, un record historique. Qui se présente devant nous ce soir? Est-ce l\\'ex-Premier ministre, le futur Premier ministre, un médiateur? Qui? Bah, le Premier ministre qui a démissionné, qui a remis la démission du gouvernement lundi matin, donc j\\'expédie les affaires courantes. Il est vrai que depuis 48h, le Président de la République m\\'a fait revenir lundi après-midi, considérant que les 3 semaines que j\\'avais passées dans le secret, parfois, ou plus ou moins public publiquement avec les\"\n",
      "    words {\n",
      "      word: \"Cornu.\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Bonsoir.\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Jusqu\\'à\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"7\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"millions\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"de\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"téléspectateurs\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"suivent\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"cette\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"interview,\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"un\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"record\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"historique.\"\n",
      "      speaker_label: \"2\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Qui\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"se\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"présente\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"devant\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"nous\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ce\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"soir?\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Est-ce\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"l\\'ex-Premier\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ministre,\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"le\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"futur\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Premier\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ministre,\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"un\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"médiateur?\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Qui?\"\n",
      "      speaker_label: \"0\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Bah,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"le\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Premier\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ministre\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"qui\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"a\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"démissionné,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"qui\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"a\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"remis\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"la\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"démission\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"du\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"gouvernement\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"lundi\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"matin,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"donc\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"j\\'expédie\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"les\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"affaires\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"courantes.\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Il\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"est\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"vrai\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"que\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"depuis\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"48h,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"le\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"Président\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"de\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"la\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"République\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"m\\'a\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"fait\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"revenir\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"lundi\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"après-midi,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"considérant\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"que\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"les\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"3\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"semaines\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"que\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"j\\'avais\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"passées\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"dans\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"le\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"secret,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"parfois,\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ou\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"plus\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"ou\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"moins\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"public\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"publiquement\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"avec\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "    words {\n",
      "      word: \"les\"\n",
      "      speaker_label: \"1\"\n",
      "    }\n",
      "  }\n",
      "  language_code: \"fr-FR\"\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[32m2025-12-25 23:07:38.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtranscription_gcp\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTranscription completed in 2.84 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "script_final, billed_duration= transcription_gcp(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "412d8a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Locuteur 0: Cornu.',\n",
       " 'Locuteur 1: Bonsoir.',\n",
       " \"Locuteur 2: Jusqu'à 7 millions de téléspectateurs suivent cette interview, un record historique.\",\n",
       " \"Locuteur 0: Qui se présente devant nous ce soir? Est-ce l'ex-Premier ministre, le futur Premier ministre, un médiateur? Qui?\",\n",
       " \"Locuteur 1: Bah, le Premier ministre qui a démissionné, qui a remis la démission du gouvernement lundi matin, donc j'expédie les affaires courantes. Il est vrai que depuis 48h, le Président de la République m'a fait revenir lundi après-midi, considérant que les 3 semaines que j'avais passées dans le secret, parfois, ou plus ou moins public publiquement avec les\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4f9e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billed_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5d5e0",
   "metadata": {},
   "source": [
    "Option Open Source: (Hugging Face/ pyannote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2427de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf_api_key = getpass.getpass('Hugging Face API key here:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07b88c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94484a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_pyannote(filename,hf_api,groq_key): #\n",
    "    logger.info(\"Démarrage de la diarisation (Pyannote)...\")\n",
    "    pipeline = Pipeline.from_pretrained(\n",
    "        \"pyannote/speaker-diarization-3.1\", \n",
    "        use_auth_token=hf_api\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pipeline.to(device)\n",
    "\n",
    "    diarization = pipeline(filename)\n",
    "    logger.info(\"Diarisation terminée.\")\n",
    "\n",
    "    logger.info(\"Démarrage de la transcription (Groq)...\")\n",
    "    client = Groq(api_key=groq_key)\n",
    "    \n",
    "    inicio_total = time.time()\n",
    "    with open(filename, \"rb\") as file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            file=(filename, file.read()),\n",
    "            model=\"whisper-large-v3-turbo\",\n",
    "            temperature=0,\n",
    "            response_format=\"verbose_json\",\n",
    "            language='fr'\n",
    "        )\n",
    "    \n",
    "    logger.info(\"Fusion des résultats et création du script...\")\n",
    "    \n",
    "    script_final = []\n",
    "    dernier_locuteur = None\n",
    "    bloc_texte = \"\"\n",
    "\n",
    "  \n",
    "    for seg in transcription.segments:\n",
    "        start_seg = seg['start']\n",
    "        end_seg = seg['end']\n",
    "        texte = seg['text'].strip()\n",
    "        \n",
    "     \n",
    "        milieu = (start_seg + end_seg) / 2\n",
    "        locuteur_actuel = \"Inconnu\"\n",
    "        \n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            if turn.start <= milieu <= turn.end:\n",
    "                locuteur_actuel = speaker\n",
    "                break\n",
    "        \n",
    "    \n",
    "        if locuteur_actuel == dernier_locuteur:\n",
    "            bloc_texte += \" \" + texte\n",
    "        else:\n",
    "  \n",
    "            if dernier_locuteur is not None:\n",
    "                script_final.append(f\"[{dernier_locuteur}] : {bloc_texte}\")\n",
    "            dernier_locuteur = locuteur_actuel\n",
    "            bloc_texte = texte\n",
    "\n",
    "   \n",
    "    if bloc_texte:\n",
    "        script_final.append(f\"[{dernier_locuteur}] : {bloc_texte}\")\n",
    "\n",
    "      \n",
    "    fin_total = time.time()\n",
    "    logger.info(f\"Processus terminé en {fin_total - inicio_total:.2f}s.\")\n",
    "    \n",
    "    return script_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbe92a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-26 10:23:34.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtranscription_pyannote\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDémarrage de la diarisation (Pyannote)...\u001b[0m\n",
      "/home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/segmentation-3.0' model.\n",
      "It might be because the model is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Model.from_pretrained('pyannote/segmentation-3.0',\n",
      "   ...                       use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the model is gated:\n",
      "visit https://hf.co/pyannote/segmentation-3.0 to accept the user conditions.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m transcription = \u001b[43mtranscription_pyannote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhf_api_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgroq_api_key\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtranscription_pyannote\u001b[39m\u001b[34m(filename, hf_api, groq_key)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranscription_pyannote\u001b[39m(filename,hf_api,groq_key): \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      2\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mDémarrage de la diarisation (Pyannote)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     pipeline = \u001b[43mPipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyannote/speaker-diarization-3.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_api\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     pipeline.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/pyannote/audio/core/pipeline.py:138\u001b[39m, in \u001b[36mPipeline.from_pretrained\u001b[39m\u001b[34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001b[39m\n\u001b[32m    136\u001b[39m params = config[\u001b[33m\"\u001b[39m\u001b[33mpipeline\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    137\u001b[39m params.setdefault(\u001b[33m\"\u001b[39m\u001b[33muse_auth_token\u001b[39m\u001b[33m\"\u001b[39m, use_auth_token)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m pipeline = \u001b[43mKlass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# freeze  parameters\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfreeze\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/pyannote/audio/pipelines/speaker_diarization.py:130\u001b[39m, in \u001b[36mSpeakerDiarization.__init__\u001b[39m\u001b[34m(self, segmentation, segmentation_step, embedding, embedding_exclude_overlap, clustering, embedding_batch_size, segmentation_batch_size, der_variant, use_auth_token)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    129\u001b[39m \u001b[38;5;28mself\u001b[39m.segmentation_model = segmentation\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m model: Model = \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.segmentation_step = segmentation_step\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m.embedding = embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/pyannote/audio/pipelines/utils/getter.py:89\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(model, use_auth_token)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     85\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) for loading model: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected `str` or `dict`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m()\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "transcription = transcription_pyannote(filename,hf_api_key,groq_api_key) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5deaa",
   "metadata": {},
   "source": [
    "For the enterprise option in here: https://dashboard.pyannote.ai/signin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b516951",
   "metadata": {},
   "source": [
    "Wisper X \n",
    "https://aicloudautomation.net/projects/whisperx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bbcdd957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/m-bain/whisperx.git\n",
      "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-5r8wrwjl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-5r8wrwjl\n",
      "  Resolved https://github.com/m-bain/whisperx.git to commit d32ec3e3012ec4c0934f4088424c32f3f038b249\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ctranslate2>=4.5.0 (from whisperx==3.7.4)\n",
      "  Downloading ctranslate2-4.6.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (10 kB)\n",
      "Collecting faster-whisper>=1.1.1 (from whisperx==3.7.4)\n",
      "  Downloading faster_whisper-1.2.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting nltk>=3.9.1 (from whisperx==3.7.4)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas<2.3.0,>=2.2.3 (from whisperx==3.7.4)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting av<16.0.0 (from whisperx==3.7.4)\n",
      "  Downloading av-15.1.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting numpy<2.3.0,>=2.1.0 (from whisperx==3.7.4)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pyannote-audio<4.0.0,>=3.3.2 (from whisperx==3.7.4)\n",
      "  Downloading pyannote_audio-3.4.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch~=2.8.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from whisperx==3.7.4) (2.8.0)\n",
      "Requirement already satisfied: torchaudio~=2.8.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from whisperx==3.7.4) (2.8.0)\n",
      "Requirement already satisfied: transformers>=4.48.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from whisperx==3.7.4) (4.57.3)\n",
      "Requirement already satisfied: triton>=3.3.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from whisperx==3.7.4) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.4) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pandas<2.3.0,>=2.2.3->whisperx==3.7.4) (2025.3)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.8.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.13.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.36.0)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.6.0)\n",
      "Collecting omegaconf<3.0,>=2.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyannote.core<6.0,>=5.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.database<6.0,>=5.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyannote.metrics<4.0,>=3.2 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyannote.pipeline<4.0,>=3.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Requirement already satisfied: pytorch_metric_learning>=2.1.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.9.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (14.2.0)\n",
      "Collecting semver>=3.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.13.1)\n",
      "Collecting speechbrain>=1.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch_audiomentations>=0.11.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.12.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.8.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (6.0.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.16.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (4.15.0)\n",
      "Collecting typer>=0.12.1 (from pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading typer-0.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.8.0)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.7.7 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.10.8)\n",
      "Requirement already satisfied: sympy>=1.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.14.0)\n",
      "Requirement already satisfied: optuna>=3.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (4.6.0)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (4.67.1)\n",
      "Requirement already satisfied: filelock>=3.0.10 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.20.1)\n",
      "Requirement already satisfied: setuptools in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (80.9.0)\n",
      "Requirement already satisfied: networkx in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch~=2.8.0->whisperx==3.7.4) (1.13.1.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from faster-whisper>=1.1.1->whisperx==3.7.4) (0.22.1)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper>=1.1.1->whisperx==3.7.4)\n",
      "  Downloading onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.4)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.4)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: packaging in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.4) (25.0)\n",
      "Requirement already satisfied: protobuf in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.4) (5.29.5)\n",
      "Requirement already satisfied: requests in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.15.2)\n",
      "Requirement already satisfied: pytorch-lightning in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.3.1)\n",
      "Requirement already satisfied: click in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from nltk>=3.9.1->whisperx==3.7.4) (8.3.1)\n",
      "Requirement already satisfied: joblib in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from nltk>=3.9.1->whisperx==3.7.4) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from nltk>=3.9.1->whisperx==3.7.4) (2025.11.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.17.2)\n",
      "Requirement already satisfied: colorlog in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.0.45)\n",
      "Requirement already satisfied: Mako in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx==3.7.4) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.23)\n",
      "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting sentencepiece (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from sympy>=1.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.2.5)\n",
      "Requirement already satisfied: primePy>=1.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (1.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from transformers>=4.48.0->whisperx==3.7.4) (0.7.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx==3.7.4)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading ruamel_yaml-0.18.17-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.15 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4)\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from jinja2->torch~=2.8.0->whisperx==3.7.4) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jeanlsoto54/.pyenv/versions/cablewatch/lib/python3.13/site-packages (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx==3.7.4) (2025.11.12)\n",
      "Downloading av-15.1.0-cp313-cp313-manylinux_2_28_x86_64.whl (39.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyannote_audio-3.4.0-py2.py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.8/897.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "Downloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "Downloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading ctranslate2-4.6.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading faster_whisper-1.2.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Downloading typer-0.21.0-py3-none-any.whl (47 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading ruamel_yaml-0.18.17-py3-none-any.whl (121 kB)\n",
      "Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.1/782.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: whisperx, antlr4-python3-runtime, docopt\n",
      "  Building wheel for whisperx (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisperx: filename=whisperx-3.7.4-py3-none-any.whl size=16485545 sha256=b8ae2b4d3b9ee4aa1dc2bde2391b761b048c82e052c8935f78f572bff2152985\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ebmpjpua/wheels/1d/63/dc/ac13737e23735605456e197d3d75bf4eaf737881c737795701\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=b444a17394563c6c9312921728ef5d93b9f1219f3496a49369a6eb6f78467ef2\n",
      "  Stored in directory: /home/jeanlsoto54/.cache/pip/wheels/d5/b3/74/a35b66048c9de6631cd74cbc9475e6feb3e69a467983446bd8\n",
      "  Building wheel for docopt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13783 sha256=a2c14b8ed554319b42e9eba14a6b0014d994b273f5eadbac86480b3f91cf1a5f\n",
      "  Stored in directory: /home/jeanlsoto54/.cache/pip/wheels/0b/1d/03/175286677fb5a1341cc3e4755bf8ec0ed08f3329afd67446b0\n",
      "Successfully built whisperx antlr4-python3-runtime docopt\n",
      "Installing collected packages: flatbuffers, docopt, antlr4-python3-runtime, tabulate, shellingham, sentencepiece, semver, ruamel.yaml.clib, omegaconf, numpy, nltk, humanfriendly, av, tensorboardX, ruamel.yaml, pandas, ctranslate2, coloredlogs, typer, pyannote.core, onnxruntime, hyperpyyaml, pyannote.database, faster-whisper, speechbrain, pyannote.pipeline, pyannote.metrics, pyannote-audio, whisperx\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [omegaconf]l.clib]ntime]\n",
      "\u001b[2K    Found existing installation: numpy 2.4.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [omegaconf]\n",
      "\u001b[2K    Uninstalling numpy-2.4.0:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.0━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandasm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [ruamel.yaml]]]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [pandas]]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: pyannote.core[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/29\u001b[0m [typer]late2]\n",
      "\u001b[2K    Found existing installation: pyannote-core 6.0.1━━━━━━━━━━\u001b[0m \u001b[32m18/29\u001b[0m [typer]\n",
      "\u001b[2K    Uninstalling pyannote-core-6.0.1:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/29\u001b[0m [typer]\n",
      "\u001b[2K      Successfully uninstalled pyannote-core-6.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m18/29\u001b[0m [typer]\n",
      "\u001b[2K  Attempting uninstall: pyannote.database91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [onnxruntime]e]\n",
      "\u001b[2K    Found existing installation: pyannote-database 6.1.1━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [onnxruntime]\n",
      "\u001b[2K    Uninstalling pyannote-database-6.1.1:\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [onnxruntime]\n",
      "\u001b[2K      Successfully uninstalled pyannote-database-6.1.1━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [onnxruntime]\n",
      "\u001b[2K  Attempting uninstall: pyannote.pipeline\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [speechbrain]er]se]\n",
      "\u001b[2K    Found existing installation: pyannote-pipeline 4.0.0━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [speechbrain]\n",
      "\u001b[2K    Uninstalling pyannote-pipeline-4.0.0:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [speechbrain]\n",
      "\u001b[2K      Successfully uninstalled pyannote-pipeline-4.0.00m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [speechbrain]\n",
      "\u001b[2K  Attempting uninstall: pyannote.metrics━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m25/29\u001b[0m [pyannote.pipeline]\n",
      "\u001b[2K    Found existing installation: pyannote-metrics 4.0.00m━━━━━\u001b[0m \u001b[32m25/29\u001b[0m [pyannote.pipeline]\n",
      "\u001b[2K    Uninstalling pyannote-metrics-4.0.0:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m25/29\u001b[0m [pyannote.pipeline]\n",
      "\u001b[2K      Successfully uninstalled pyannote-metrics-4.0.0[90m━━━━━\u001b[0m \u001b[32m25/29\u001b[0m [pyannote.pipeline]\n",
      "\u001b[2K  Attempting uninstall: pyannote-audio━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [pyannote.metrics]\n",
      "\u001b[2K    Found existing installation: pyannote-audio 4.0.3m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m27/29\u001b[0m [pyannote-audio]\n",
      "\u001b[2K    Uninstalling pyannote-audio-4.0.3:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m27/29\u001b[0m [pyannote-audio]\n",
      "\u001b[2K      Successfully uninstalled pyannote-audio-4.0.3\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m27/29\u001b[0m [pyannote-audio]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [whisperx]/29\u001b[0m [whisperx]audio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed antlr4-python3-runtime-4.9.3 av-15.1.0 coloredlogs-15.0.1 ctranslate2-4.6.2 docopt-0.6.2 faster-whisper-1.2.1 flatbuffers-25.12.19 humanfriendly-10.0 hyperpyyaml-1.2.2 nltk-3.9.2 numpy-2.2.6 omegaconf-2.3.0 onnxruntime-1.23.2 pandas-2.2.3 pyannote-audio-3.4.0 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 ruamel.yaml-0.18.17 ruamel.yaml.clib-0.2.15 semver-3.0.4 sentencepiece-0.2.1 shellingham-1.5.4 speechbrain-1.0.3 tabulate-0.9.0 tensorboardX-2.6.4 typer-0.21.0 whisperx-3.7.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8409c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-26 00:43:15 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
      "2025-12-26 00:43:15 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.6.0. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint ../../../../../.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/assets/pytorch_model.bin`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Inference.__init__() got an unexpected keyword argument 'use_auth_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m batch_size = \u001b[32m16\u001b[39m \n\u001b[32m      7\u001b[39m compute_type = \u001b[33m\"\u001b[39m\u001b[33mfloat16\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model = \u001b[43mwhisperx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlarge-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m audio = whisperx.load_audio(audio_file)\n\u001b[32m     11\u001b[39m result = model.transcribe(audio, batch_size=batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/__init__.py:21\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(*args, **kwargs):\n\u001b[32m     20\u001b[39m     asr = _lazy_import(\u001b[33m\"\u001b[39m\u001b[33masr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/asr.py:412\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(whisper_arch, device, device_index, compute_type, asr_options, language, vad_model, vad_method, vad_options, model, task, download_root, local_files_only, threads)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    411\u001b[39m         device_vad = device\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m     vad_model = \u001b[43mPyannote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_vad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdefault_vad_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid vad_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvad_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/vads/pyannote.py:240\u001b[39m, in \u001b[36mPyannote.__init__\u001b[39m\u001b[34m(self, device, use_auth_token, model_fp, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mPerforming voice activity detection using Pyannote...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(kwargs[\u001b[33m'\u001b[39m\u001b[33mvad_onset\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28mself\u001b[39m.vad_pipeline = \u001b[43mload_vad_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_fp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/vads/pyannote.py:48\u001b[39m, in \u001b[36mload_vad_model\u001b[39m\u001b[34m(device, vad_onset, vad_offset, use_auth_token, model_fp)\u001b[39m\n\u001b[32m     43\u001b[39m vad_model = Model.from_pretrained(model_fp, use_auth_token=use_auth_token)\n\u001b[32m     44\u001b[39m hyperparameters = {\u001b[33m\"\u001b[39m\u001b[33monset\u001b[39m\u001b[33m\"\u001b[39m: vad_onset,\n\u001b[32m     45\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33moffset\u001b[39m\u001b[33m\"\u001b[39m: vad_offset,\n\u001b[32m     46\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmin_duration_on\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m,\n\u001b[32m     47\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmin_duration_off\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m vad_pipeline = \u001b[43mVoiceActivitySegmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvad_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m vad_pipeline.instantiate(hyperparameters)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vad_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/whisperx/vads/pyannote.py:199\u001b[39m, in \u001b[36mVoiceActivitySegmentation.__init__\u001b[39m\u001b[34m(self, segmentation, fscore, use_auth_token, **inference_kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    193\u001b[39m         segmentation: PipelineModel = \u001b[33m\"\u001b[39m\u001b[33mpyannote/segmentation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m         **inference_kwargs,\n\u001b[32m    197\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m=\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/cablewatch/lib/python3.13/site-packages/pyannote/audio/pipelines/voice_activity_detection.py:114\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, segmentation, fscore, token, cache_dir, **inference_kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mVoiceActivityDetection\u001b[39;00m(Pipeline):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Voice activity detection pipeline\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m        Fill non-speech regions shorter than that many seconds.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    111\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    112\u001b[39m         segmentation: PipelineModel = \u001b[33m\"\u001b[39m\u001b[33mpyannote/segmentation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m         fscore: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         use_auth_token: Union[Text, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    115\u001b[39m         **inference_kwargs,\n\u001b[32m    116\u001b[39m     ):\n\u001b[32m    117\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    119\u001b[39m         \u001b[38;5;28mself\u001b[39m.segmentation = segmentation\n",
      "\u001b[31mTypeError\u001b[39m: Inference.__init__() got an unexpected keyword argument 'use_auth_token'"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "\n",
    "device = \"cuda\" \n",
    "audio_file = filename\n",
    "batch_size = 16 \n",
    "compute_type = \"float16\"\n",
    "\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n",
    "audio = whisperx.load_audio(audio_file)\n",
    "result = model.transcribe(audio, batch_size=batch_size)\n",
    "\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "diarize_model = whisperx.DiarizationPipeline(use_auth_token=hf_api_key, device=device)\n",
    "diarize_segments = diarize_model(audio)\n",
    "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "\n",
    "# 4. Print results\n",
    "for segment in result[\"segments\"]:\n",
    "    print(f\"[{segment['speaker']}] {segment['start']:.2f}s: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375d5ec",
   "metadata": {},
   "source": [
    "Nemo Envidia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba27358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.models import ASRModel\n",
    "from nemo.collections.asr.models.speaker_models import SpkrEmbeddingLabelModel\n",
    "\n",
    "# Load pretrained speaker diarization model\n",
    "model = SpkrEmbeddingLabelModel.from_pretrained(\"nvidia/speakerverification_en_titanet_large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_diarizer.diarizer import Diarizer\n",
    "\n",
    "diarizer = Diarizer()\n",
    "segments = diarizer.diarize(\"audio.wav\", num_speakers=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cablewatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
